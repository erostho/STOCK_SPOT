# ===========================
#  VN STOCK BOT: FireAnt + VNDIRECT
#  B1: FireAnt -> tickers < 10k (nh·∫π)
#  B2: VNDIRECT -> FA (cache 7 ng√†y)
#  B3: VNDIRECT -> TA (realtime m·ªói l·∫ßn scan)
# ===========================

import os, json, time, sys
import requests
import pandas as pd
import ta
from datetime import datetime, timedelta
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
import time
# ---------- ENV ----------
FINFO_BASE = "https://finfo-api.vndirect.com.vn/v4"
FR_URL     = f"{FINFO_BASE}/financial_reports"
PRICE_URL  = f"{FINFO_BASE}/stock_prices"

# FireAnt free: thay endpoint/token theo th·ª±c t·∫ø c·ªßa b·∫°n
FIREANT_BASE = os.getenv("FIREANT_BASE", "https://restv2.fireant.vn/symbols")  # v√≠ d·ª•
FIREANT_TOKEN = (os.getenv("FIREANT_TOKEN") or "").strip()

TELEGRAM_TOKEN = (os.getenv("TELEGRAM_TOKEN") or os.getenv("TELEGRAM_BOT_TOKEN") or "").strip()
TELEGRAM_CHAT_ID = (os.getenv("TELEGRAM_CHAT_ID") or "").strip()

CACHE_DIR = "/tmp/vnstock_cache"
os.makedirs(CACHE_DIR, exist_ok=True)

def log(msg):
    print(f"[{datetime.now().strftime('%H:%M:%S')}] {msg}", flush=True)

# ---------- HTTP SESSION ----------
def make_session():
    s = requests.Session()
    s.headers.update({
        "User-Agent": "vnstock-bot/1.0",
        "Accept-Encoding": "gzip, deflate, br",
        "Connection": "keep-alive"
    })
    retry = Retry(
        total=5, connect=5, read=5,
        backoff_factor=0.8,
        status_forcelist=[429,500,502,503,504],
        allowed_methods=["GET"]
    )
    s.mount("https://", HTTPAdapter(pool_connections=20, pool_maxsize=20, max_retries=retry))
    s.mount("http://",  HTTPAdapter(pool_connections=20, pool_maxsize=20, max_retries=retry))
    return s

SESSION = make_session()

# ---------- CACHE ----------
def cache_get(name, ttl_sec):
    p = os.path.join(CACHE_DIR, name)
    try:
        if os.path.exists(p) and (time.time() - os.path.getmtime(p) < ttl_sec):
            with open(p, "r", encoding="utf-8") as f:
                return json.load(f)
    except Exception:
        pass
    return None

def cache_set(name, obj):
    p = os.path.join(CACHE_DIR, name)
    try:
        with open(p, "w", encoding="utf-8") as f:
            json.dump(obj, f)
    except Exception:
        pass

# ============================================================
# B1) L·∫§Y DANH S√ÅCH <10K T·ª™ SSI
# ============================================================

def get_tickers_under_10k_from_vnd_prices():
    """
    L·∫•y danh s√°ch m√£ <10k t·ª´ VNDIRECT /v4/stock_prices
    - Chia theo s√†n HOSE/HNX/UPCOM
    - Ph√¢n trang size nh·ªè ƒë·ªÉ tr√°nh timeout
    """
    log("üì• VNDIRECT: stock_prices paginate ƒë·ªÉ l·ªçc <10k ‚Ä¶")
    markets = ["HOSE", "HNX", "UPCOM"]
    size = 180                 # nh·ªè ƒë·ªÉ nh·∫π server
    max_pages = 6              # 6 * 180 ~ 1080/market
    all_tickers = set()
    last_err = None

    for m in markets:
        for page in range(1, max_pages + 1):
            try:
                params = {"q": f"market:{m}", "page": page, "size": size, "sort": "ticker"}
                r = SESSION.get(PRICE_URL, params=params, timeout=(8, 18))
                r.raise_for_status()
                rows = r.json().get("data", [])
                if not rows:
                    break
                df = pd.DataFrame(rows)
                # c·ªôt gi√° c√≥ th·ªÉ l√† adclose/close
                price = None
                for col in ["adclose", "close", "matchPrice", "price"]:
                    if col in df.columns:
                        price = pd.to_numeric(df[col], errors="coerce")
                        break
                if price is None:
                    break
                tks = df.loc[(price > 0) & (price < 10000), "ticker"].dropna().astype(str).str.upper().unique().tolist()
                all_tickers.update(tks)
                log(f"  ‚Ü≥ {m} page {page}: +{len(tks)} m√£ (t·ªïng t·∫°m {len(all_tickers)})")
                time.sleep(0.25)
            except Exception as e:
                last_err = e
                log(f"‚ö†Ô∏è {m} page {page} l·ªói: {e}")
                # trang n√†y l·ªói th√¨ th·ª≠ trang k·∫ø, tr√°nh k·∫πt
                time.sleep(0.6)
                continue

    tks = sorted(all_tickers)
    log(f"üìä VNDIRECT paginate xong: {len(tks)} m√£ <10k.")
    return tks
    
# ===== SHEET: l·∫•y tickers <10 t·ª´ Google Sheet =====
# Y√™u c·∫ßu: t·∫°o link CSV c√¥ng khai v√† ƒë·∫∑t v√†o env SHEET_CSV_URL
# M·∫´u URL: https://docs.google.com/spreadsheets/d/<SPREADSHEET_ID>/gviz/tq?tqx=out:csv&sheet=DANH%20M·ª§C%20CP

def get_tickers_under_10k_from_sheet():
    import pandas as pd, re
    url = os.getenv("SHEET_CSV_URL", "").strip()
    if not url:
        log("‚ö†Ô∏è SHEET_CSV_URL ch∆∞a c·∫•u h√¨nh. V√†o Google Sheet -> Share: Anyone with link (Viewer) -> d√πng link CSV gviz.")
        return []

    log("üì• Sheet: ƒë·ªçc 'DANH M·ª§C CP' (C=M√£, K=Th·ªã gi√°) & l·ªçc < 10 ‚Ä¶")
    try:
        # ƒê·ªçc CSV c·ªßa sheet "DANH M·ª§C CP"
        df = pd.read_csv(url)

        # ∆Øu ti√™n b·∫Øt theo ti√™u ƒë·ªÅ; n·∫øu kh√¥ng c√≥ th√¨ fallback theo v·ªã tr√≠ c·ªôt C/K
        col_ticker = None
        for name in df.columns:
            if str(name).strip().lower() in ["m√£", "ma", "ticker", "symbol", "code"]:
                col_ticker = name
                break
        if col_ticker is None and df.shape[1] >= 3:
            col_ticker = df.columns[2]  # c·ªôt C (0-based index = 2)

        col_price = None
        for name in df.columns:
            if re.sub(r"\s+", "", str(name).strip().lower()) in ["th·ªãgi√°","thigia","gia","price"]:
                col_price = name
                break
        if col_price is None and df.shape[1] >= 11:
            col_price = df.columns[10]  # c·ªôt K (0-based index = 10)

        if col_ticker is None or col_price is None:
            log(f"‚ùå Kh√¥ng t√¨m th·∫•y c·ªôt: ticker={col_ticker}, price={col_price}")
            return []

        # Chu·∫©n ho√° gi√° (sheet c√≥ th·ªÉ c√≥ d·∫•u ch·∫•m ph·∫©y, k√Ω t·ª±)
        price = (df[col_price].astype(str)
                 .str.replace(r"[^\d,\.]", "", regex=True)
                 .str.replace(".", "", regex=False)
                 .str.replace(",", ".", regex=False))
        price = pd.to_numeric(price, errors="coerce")

        # L·ªçc < 10 theo y√™u c·∫ßu (ƒë√¢y l√† ƒë∆°n v·ªã nh∆∞ tr√™n sheet c·ªßa b·∫°n)
        mask = (price > 0) & (price < 10)
        tks = (df.loc[mask, col_ticker]
                 .astype(str).str.upper().str.strip()
                 .dropna().unique().tolist())
        tks = sorted(set(tks))

        log(f"‚úÖ Sheet l·ªçc ƒë∆∞·ª£c {len(tks)} m√£ <10.")
        # L∆∞u cache 24h ƒë·ªÉ ph√≤ng khi sheet l·ªói m·∫°ng
        cache_set("tickers_under_10k.json", {"tickers": tks, "src": "sheet"})
        return tks

    except Exception as e:
        log(f"‚ùå L·ªói ƒë·ªçc sheet: {e}")
        # D√πng cache n·∫øu c√≥
        cached = cache_get("tickers_under_10k.json", ttl_sec=24*3600)
        if cached and cached.get("tickers"):
            log(f"üü° D√πng cache: {len(cached['tickers'])} m√£")
            return cached["tickers"]
        return []

# ============================================================
# B2) FA T·ª™ VNDIRECT (C√ì CACHE 7 NG√ÄY) - CH·∫†Y RI√äNG
# ============================================================
def get_fr_one_ticker_vnd(tk):
    try:
        params = {"q": f"ticker:{tk}~reportType:QUARTER", "size": 8, "sort": "-yearQuarter"}
        r = SESSION.get(FR_URL, params=params, timeout=(8, 18))
        r.raise_for_status()
        return r.json().get("data", [])
    except Exception as e:
        log(f"‚ö†Ô∏è {tk} FR l·ªói: {e}")
        return []

def run_fa_update(tickers):
    """T·∫£i FA cho list tickers v√† l∆∞u cache 7 ng√†y: fa_cache.json"""
    if not tickers:
        log("‚ùå Kh√¥ng c√≥ tickers ƒë·ªÉ c·∫≠p nh·∫≠t FA.")
        return []
    log(f"üßæ C·∫≠p nh·∫≠t FA cho {len(tickers)} m√£ ‚Ä¶")
    out = []
    for i, tk in enumerate(tickers, 1):
        out.extend(get_fr_one_ticker_vnd(tk))
        if i % 25 == 0:
            log(f"‚Ä¶ƒë√£ l·∫•y {i}/{len(tickers)} m√£ FA")
            time.sleep(0.3)
    df = pd.DataFrame(out)
    cache_set("fa_cache.json", {"rows": out, "ts": int(time.time())})
    log(f"‚úÖ L∆∞u cache FA: {len(df)} d√≤ng (7 ng√†y)")
    return df

def load_fa_cache():
    cached = cache_get("fa_cache.json", ttl_sec=7*24*3600)
    if cached and cached.get("rows"):
        return pd.DataFrame(cached["rows"])
    return pd.DataFrame()

def analyze_fa(df_quarter: pd.DataFrame):
    """FA filter b·∫Øt bu·ªôc (gi·ªëng tr∆∞·ªõc): EPS>500, ROE>10, 0<PE<10, Debt/Equity<1, CFO TTM +, LNST YoY +, t·ªìn kho YoY <=30%."""
    if df_quarter.empty:
        return []
    fa_pass = []
    for ticker, sub in df_quarter.groupby("ticker"):
        sub = sub.sort_values(by="yearQuarter", ascending=False).head(8)
        latest = sub.iloc[0].to_dict()

        def f(row, key, default=0.0):
            try:
                v = row.get(key, default)
                return float(v) if pd.notna(v) else default
            except Exception:
                return default

        price = f(latest, "price")
        eps   = f(latest, "eps")
        pe    = f(latest, "pe")
        roe   = f(latest, "roe")
        inv   = f(latest, "inventory")
        liab  = f(latest, "liabilities")
        eq    = f(latest, "equity")

        lnst_q = pd.to_numeric(sub.get("netProfit"), errors="coerce").fillna(0.0).values.tolist()
        cfo_q  = pd.to_numeric(sub.get("netCashFlowFromOperatingActivities"), errors="coerce").fillna(0.0).values.tolist()

        inv_yoy = None
        if len(sub) >= 5:
            inv_yoy = f(sub.iloc[4].to_dict(), "inventory", None)

        # ƒêi·ªÅu ki·ªán
        if not (0 < price < 10000): continue
        if not (eps > 500): continue
        if not (roe > 10):  continue
        if not (0 < pe < 10): continue
        if eq <= 0 or (liab/eq) >= 1.0: continue
        cfo_ttm = sum(cfo_q[:4]) if len(cfo_q) >= 4 else sum(cfo_q)
        if cfo_ttm <= 0: continue
        lnst_yoy_ok = False
        if len(lnst_q) >= 5:
            lnst_yoy_ok = lnst_q[0] > lnst_q[4]
        elif len(lnst_q) >= 8:
            lnst_yoy_ok = sum(lnst_q[:4]) > sum(lnst_q[4:8])
        if not lnst_yoy_ok: continue
        if inv_yoy and inv_yoy > 0:
            if (inv - inv_yoy) / inv_yoy > 0.30:
                continue

        fa_pass.append({
            "ticker": ticker,
            "price": price,
            "eps": eps,
            "roe": roe,
            "pe": pe
        })
    log(f"‚úÖ FA PASS: {len(fa_pass)} m√£")
    return fa_pass

# ============================================================
# B3) TA T·ª™ VNDIRECT (REALTIME M·ªñI L·∫¶N CH·∫†Y)
# ============================================================
import time
from datetime import datetime, timedelta

def get_ohlc_days_tcbs(ticker: str, days: int = 180):
    """
    L·∫•y OHLC daily t·ª´ TCBS (public, no token) cho TA EOD.
    Tr·∫£ v·ªÅ DataFrame c√≥ c·ªôt: date, open, high, low, close, volume
    """
    tk = str(ticker).upper().strip()
    # kho·∫£ng th·ªùi gian (buffer l·ªõn h∆°n 20% ƒë·ªÉ ch·∫Øc ch·∫Øn ƒë·ªß phi√™n)
    to_dt   = datetime.utcnow()
    from_dt = to_dt - timedelta(days=int(days * 1.3))
    to_s, from_s = int(to_dt.timestamp()), int(from_dt.timestamp())

    url = ("https://apipubaws.tcbs.com.vn/stock-insight/v1/stock/"
           f"bars-long-term?symbol={tk}&type=stock&resolution=D&from={from_s}&to={to_s}")
    headers = {"User-Agent": "Mozilla/5.0", "Accept": "application/json"}

    last_err = None
    for attempt in range(1, 3+1):
        try:
            r = requests.get(url, headers=headers, timeout=(6, 12))
            r.raise_for_status()
            js = r.json() or {}
            rows = js.get("data", js)  # TCBS tr·∫£ {"data":[...]} ho·∫∑c list
            df = pd.DataFrame(rows)
            if df.empty:
                raise RuntimeError("TCBS tr·∫£ r·ªóng")

            # Chu·∫©n ho√° c·ªôt, TCBS th∆∞·ªùng d√πng keys: o,h,l,c,v,t (t = epoch seconds)
            rename_map = {}
            for a, b in [("o","open"),("h","high"),("l","low"),("c","close"),("v","volume")]:
                if a in df.columns: rename_map[a] = b
            if "t" in df.columns:
                df["date"] = pd.to_datetime(df["t"], unit="s").dt.date
            elif "time" in df.columns:
                df["date"] = pd.to_datetime(df["time"]).dt.date
            df = df.rename(columns=rename_map)
            cols = ["date","open","high","low","close","volume"]
            df = df[[c for c in cols if c in df.columns]].dropna().sort_values("date").reset_index(drop=True)

            # Gi·ªØ l·∫°i ƒë√∫ng s·ªë ng√†y y√™u c·∫ßu (n·∫øu c·∫ßn)
            if len(df) > days:
                df = df.iloc[-days:].reset_index(drop=True)

            return df
        except Exception as e:
            last_err = e
            log(f"‚ö†Ô∏è OHLC {tk} TCBS attempt {attempt}/3 l·ªói: {e}")
            time.sleep(0.6)
    log(f"‚ùå TCBS kh√¥ng kh·∫£ d·ª•ng cho {tk}: {last_err}")
    return pd.DataFrame()

def get_ohlc_days_vnd(ticker, days=120):
    start = (datetime.now() - timedelta(days=days*2)).strftime("%Y-%m-%d")
    params = {"q": f"ticker:{ticker}~date:gte:{start}", "sort": "date", "size": 1000}
    try:
        r = SESSION.get(PRICE_URL, params=params, timeout=(8, 18))
        r.raise_for_status()
        data = r.json().get("data", [])
        if not data: return pd.DataFrame()
        df = pd.DataFrame(data)
        for c,n in [("adOpen","open"),("adHigh","high"),("adLow","low"),("adClose","close"),("adVolume","volume")]:
            if c in df.columns:
                df[n] = pd.to_numeric(df[c], errors="coerce")
        df = df[["date","open","high","low","close","volume"]].dropna().sort_values("date")
        return df.tail(150)
    except Exception as e:
        log(f"‚ö†Ô∏è OHLC {ticker} l·ªói: {e}")
        return pd.DataFrame()

def technical_signals(df: pd.DataFrame):
    """
    5 ƒëi·ªÅu ki·ªán TA:
      - ADX > 20 & DI+ > DI-
      - RSI > 50 v√† v·ª´a c·∫Øt l√™n
      - Break ƒë·ªânh 20 phi√™n
      - Volume tƒÉng 3 phi√™n li√™n ti·∫øp
      - Close > MA20 & Volume Spike
    """
    conds = {}
    if df is None or len(df) < 25:
        conds["enough_data"] = False
        conds["score_TA_true"] = 0
        return conds, 0

    rsi_ind = ta.momentum.RSIIndicator(close=df["close"], window=14)
    df["rsi"] = rsi_ind.rsi()
    adx_ind = ta.trend.ADXIndicator(high=df["high"], low=df["low"], close=df["close"], window=14)
    df["adx"] = adx_ind.adx()
    df["di_pos"] = adx_ind.adx_pos()
    df["di_neg"] = adx_ind.adx_neg()
    df["ma20"] = df["close"].rolling(20).mean()
    df["vol_ma20"] = df["volume"].rolling(20).mean()

    latest = df.iloc[-1]; prev = df.iloc[-2]
    conds["ADX>20_DI+>DI-"]   = bool((latest["adx"] > 20) and (latest["di_pos"] > latest["di_neg"]))
    conds["RSI>50_cross_up"]  = bool((latest["rsi"] > 50) and (prev["rsi"] <= 50))
    conds["Break_20_high"]    = bool(latest["close"] > float(df["close"].iloc[-20:-1].max()))
    conds["Vol_up_3_days"]    = bool(df["volume"].iloc[-1] > df["volume"].iloc[-2] > df["volume"].iloc[-3])
    conds["Close>MA20_VolSp"] = bool((latest["close"] > latest["ma20"]) and (latest["volume"] > 1.5 * latest["vol_ma20"]))

    score = sum(1 for v in conds.values() if v)
    conds["enough_data"] = True
    conds["score_TA_true"] = score
    return conds, score

# ============================================================
# G·ª¨I TELEGRAM
# ============================================================
def send_telegram(text):
    token = TELEGRAM_TOKEN; chat = TELEGRAM_CHAT_ID
    if not token or not chat:
        log("‚ùå Thi·∫øu TELEGRAM_TOKEN / TELEGRAM_CHAT_ID"); return
    try:
        url = f"https://api.telegram.org/bot{token}/sendMessage"
        r = requests.post(url, data={"chat_id": chat, "text": text}, timeout=15)
        if r.status_code == 200 and r.json().get("ok"):
            log("üì® Sent Telegram.")
        else:
            log(f"‚ùå Telegram {r.status_code}: {r.text}")
    except Exception as e:
        log(f"‚ùå Telegram error: {e}")

def format_msg(stocks):
    today = datetime.now().strftime("%d/%m/%Y")
    if not stocks:
        return f"üìâ [{today}] Kh√¥ng c√≥ m√£ n√†o ƒë·∫°t FA + TA."
    msg = f"üìà [{today}] M√£ <10k ƒë·∫°t FA + TA (‚â•3/5):\n\n"
    for s in stocks:
        msg += (f"‚Ä¢ {s['ticker']} | Gi√°: {int(s['price'])}ƒë | EPS:{int(s['eps'])} "
                f"| ROE:{s['roe']:.1f}% | P/E:{s['pe']:.1f} | TA‚úì:{s['ta_score']}/5\n")
    return msg

# ============================================================
# MAIN MODES
#   - python main.py list   -> ch·ªâ l·∫•y danh s√°ch <10k t·ª´ FireAnt
#   - python main.py fa     -> c·∫≠p nh·∫≠t & cache FA t·ª´ VNDIRECT
#   - python main.py scan   -> load FA cache -> qu√©t TA realtime
# ============================================================
def main():
    mode = (sys.argv[1] if len(sys.argv) > 1 else "scan").lower()
    log(f"üöÄ Start BOT mode={mode}")

    if mode == "list":
        tks = get_tickers_under_10k_from_sheet()
        log(f"Done list: {len(tks)} m√£")
        return

    if mode == "fa":
        tks = get_tickers_under_10k_from_sheet()
        if not tks:
            log("‚ö†Ô∏è Kh√¥ng c√≥ tickers t·ª´ sheet. D·ª´ng FA update.")
            return
        _ = run_fa_update(tks)
        log("FA update DONE.")
        return

    # mode == scan (default): d√πng FA cache + TA realtime
    df_fa_cache = load_fa_cache()
    fa_list = analyze_fa(df_fa_cache) if not df_fa_cache.empty else []
    
    if not fa_list:
        # üëâ TA-only: khi FA r·ªóng ho·∫∑c kh√¥ng pass
        log("üü† Kh√¥ng d√πng ƒë∆∞·ª£c FA ‚Üí chuy·ªÉn sang TA-only.")
        tks = get_tickers_under_10k_from_sheet()
        if not tks:
            send_telegram("‚ö†Ô∏è BOT: sheet kh√¥ng kh·∫£ d·ª•ng, t·∫°m d·ª´ng.")
            return
        # ch·∫°y TA cho danh s√°ch <10k, b·ªè b∆∞·ªõc FA
        final = []
        for i, tk in enumerate(tks, 1):
            log(f"[TA-only] {i}/{len(tks)} ‚Äî {tk}")
            df = get_ohlc_days_tcbs(tk, days=180)
            conds, score = technical_signals(df)
            if conds.get("enough_data") and score >= 3:
                final.append({"ticker": tk, "price": float(df['close'].iloc[-1]), "eps": 0, "roe": 0, "pe": 0, "ta_score": score})
        send_telegram(format_msg(final))
        log(f"ALL DONE (TA-only). Final={len(final)}")
        return
    
    # ‚Ä¶ n·∫øu FA c√≥ d·ªØ li·ªáu th√¨ ch·∫°y flow c≈© (FA -> TA)
    final = []
    for i, it in enumerate(fa_list, 1):
        tk = it["ticker"]
        log(f"[TA] {i}/{len(fa_list)} ‚Äî {tk}")
        df = get_ohlc_days_vnd(tk, days=180)
        conds, score = technical_signals(df)
        if conds.get("enough_data") and score >= 3:
            final.append({**it, "ta_score": score})
    
    send_telegram(format_msg(final))
    log(f"ALL DONE. Final={len(final)}")

    final = []
    for i, it in enumerate(fa_list, 1):
        tk = it["ticker"]
        log(f"[TA] {i}/{len(fa_list)} ‚Äî {tk}")
        df = get_ohlc_days_vnd(tk, days=180)
        conds, score = technical_signals(df)
        if conds.get("enough_data") and score >= 3:
            final.append({**it, "ta_score": score})

    send_telegram(format_msg(final))
    log(f"ALL DONE. Final={len(final)}")

if __name__ == "__main__":
    main()
