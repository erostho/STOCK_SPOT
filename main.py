# ===========================
#  VN STOCK BOT: FireAnt + VNDIRECT
#  B1: FireAnt -> tickers < 10k (nh·∫π)
#  B2: VNDIRECT -> FA (cache 7 ng√†y)
#  B3: VNDIRECT -> TA (realtime m·ªói l·∫ßn scan)
# ===========================

import os, json, time, sys
import requests
import pandas as pd
import ta
from datetime import datetime, timedelta
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
import time
# ---------- ENV ----------
FINFO_BASE = "https://finfo-api.vndirect.com.vn/v4"
FR_URL     = f"{FINFO_BASE}/financial_reports"
PRICE_URL  = f"{FINFO_BASE}/stock_prices"

# FireAnt free: thay endpoint/token theo th·ª±c t·∫ø c·ªßa b·∫°n
FIREANT_BASE = os.getenv("FIREANT_BASE", "https://restv2.fireant.vn/symbols")  # v√≠ d·ª•
FIREANT_TOKEN = (os.getenv("FIREANT_TOKEN") or "").strip()

TELEGRAM_TOKEN = (os.getenv("TELEGRAM_TOKEN") or os.getenv("TELEGRAM_BOT_TOKEN") or "").strip()
TELEGRAM_CHAT_ID = (os.getenv("TELEGRAM_CHAT_ID") or "").strip()

CACHE_DIR = "/tmp/vnstock_cache"
os.makedirs(CACHE_DIR, exist_ok=True)

def log(msg):
    print(f"[{datetime.now().strftime('%H:%M:%S')}] {msg}", flush=True)

# ---------- HTTP SESSION ----------
def make_session():
    s = requests.Session()
    s.headers.update({
        "User-Agent": "vnstock-bot/1.0",
        "Accept-Encoding": "gzip, deflate, br",
        "Connection": "keep-alive"
    })
    retry = Retry(
        total=5, connect=5, read=5,
        backoff_factor=0.8,
        status_forcelist=[429,500,502,503,504],
        allowed_methods=["GET"]
    )
    s.mount("https://", HTTPAdapter(pool_connections=20, pool_maxsize=20, max_retries=retry))
    s.mount("http://",  HTTPAdapter(pool_connections=20, pool_maxsize=20, max_retries=retry))
    return s

SESSION = make_session()

# ---------- CACHE ----------
def cache_get(name, ttl_sec):
    p = os.path.join(CACHE_DIR, name)
    try:
        if os.path.exists(p) and (time.time() - os.path.getmtime(p) < ttl_sec):
            with open(p, "r", encoding="utf-8") as f:
                return json.load(f)
    except Exception:
        pass
    return None

def cache_set(name, obj):
    p = os.path.join(CACHE_DIR, name)
    try:
        with open(p, "w", encoding="utf-8") as f:
            json.dump(obj, f)
    except Exception:
        pass

# ============================================================
# B1) L·∫§Y DANH S√ÅCH <10K T·ª™ SSI
# ============================================================

def get_tickers_under_10k_from_vnd_prices():
    """
    L·∫•y danh s√°ch m√£ <10k t·ª´ VNDIRECT /v4/stock_prices
    - Chia theo s√†n HOSE/HNX/UPCOM
    - Ph√¢n trang size nh·ªè ƒë·ªÉ tr√°nh timeout
    """
    log("üì• VNDIRECT: stock_prices paginate ƒë·ªÉ l·ªçc <10k ‚Ä¶")
    markets = ["HOSE", "HNX", "UPCOM"]
    size = 180                 # nh·ªè ƒë·ªÉ nh·∫π server
    max_pages = 6              # 6 * 180 ~ 1080/market
    all_tickers = set()
    last_err = None

    for m in markets:
        for page in range(1, max_pages + 1):
            try:
                params = {"q": f"market:{m}", "page": page, "size": size, "sort": "ticker"}
                r = SESSION.get(PRICE_URL, params=params, timeout=(8, 18))
                r.raise_for_status()
                rows = r.json().get("data", [])
                if not rows:
                    break
                df = pd.DataFrame(rows)
                # c·ªôt gi√° c√≥ th·ªÉ l√† adclose/close
                price = None
                for col in ["adclose", "close", "matchPrice", "price"]:
                    if col in df.columns:
                        price = pd.to_numeric(df[col], errors="coerce")
                        break
                if price is None:
                    break
                tks = df.loc[(price > 0) & (price < 10000), "ticker"].dropna().astype(str).str.upper().unique().tolist()
                all_tickers.update(tks)
                log(f"  ‚Ü≥ {m} page {page}: +{len(tks)} m√£ (t·ªïng t·∫°m {len(all_tickers)})")
                time.sleep(0.25)
            except Exception as e:
                last_err = e
                log(f"‚ö†Ô∏è {m} page {page} l·ªói: {e}")
                # trang n√†y l·ªói th√¨ th·ª≠ trang k·∫ø, tr√°nh k·∫πt
                time.sleep(0.6)
                continue

    tks = sorted(all_tickers)
    log(f"üìä VNDIRECT paginate xong: {len(tks)} m√£ <10k.")
    return tks
    
def get_tickers_under_10k_from_ssi():
    """
    L·∫•y danh s√°ch m√£ & gi√° t·ª´ SSI iBoard (public, kh√¥ng token),
    l·ªçc < 10.000 r·ªìi tr·∫£ v·ªÅ list tickers (uppercase).
    """
    log("üì• SSI: l·∫•y danh s√°ch & l·ªçc <10k ‚Ä¶ (retry ng·∫Øn)")
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115 Safari/537.36",
        "Accept": "application/json, text/plain, */*",
        "Origin": "https://iboard.ssi.com.vn",
        "Referer": "https://iboard.ssi.com.vn/"
    }

    # M·ªôt s·ªë endpoint c√¥ng khai (c√≥ th·ªÉ thay ƒë·ªïi theo th·ªùi gian):
    # 1) To√†n th·ªã tr∆∞·ªùng
    endpoints_all = [
        "https://iboard.ssi.com.vn/api/market/stock?type=All",
        "https://iboard.ssi.com.vn/api/market/stock"  # ƒë√¥i khi kh√¥ng c·∫ßn query, tr·∫£ to√†n b·ªô
    ]
    # 2) Chia theo s√†n (fallback)
    endpoints_by_floor = [
        "https://iboard.ssi.com.vn/api/market/stock?floor=HOSE",
        "https://iboard.ssi.com.vn/api/market/stock?floor=HNX",
        "https://iboard.ssi.com.vn/api/market/stock?floor=UPCOM",
    ]

    def _parse_df(rows):
        if not rows:
            return pd.DataFrame()
        df = pd.DataFrame(rows)
        # t√¨m c·ªôt gi√° ph√π h·ª£p
        price_col = next((c for c in ["lastPrice","matchPrice","price","close","refPrice","r"] if c in df.columns), None)
        if not price_col:
            return pd.DataFrame()
        price = pd.to_numeric(df[price_col], errors="coerce")
        sym_col = "symbol" if "symbol" in df.columns else ("ticker" if "ticker" in df.columns else None)
        if not sym_col:
            return pd.DataFrame()
        out = df.loc[(price > 0) & (price < 10000), [sym_col, price_col]].copy()
        out.rename(columns={sym_col: "ticker", price_col: "price"}, inplace=True)
        out["ticker"] = out["ticker"].astype(str).str.upper()
        return out

    last_err = None

    # A) th·ª≠ endpoint to√†n th·ªã tr∆∞·ªùng
    for attempt in range(1, 3+1):
        for url in endpoints_all:
            try:
                r = requests.get(url, headers=headers, timeout=(8, 18))
                r.raise_for_status()
                rows = r.json()
                df = _parse_df(rows)
                if not df.empty:
                    tks = sorted(df["ticker"].unique().tolist())
                    log(f"‚úÖ SSI(all) <10k: {len(tks)} m√£.")
                    # cache n·∫øu b·∫°n d√πng cache_get/cache_set nh∆∞ c≈©:
                    cache_set("tickers_under_10k.json", {"tickers": tks, "src": "ssi"})
                    return tks
            except Exception as e:
                last_err = e
        log(f"‚ö†Ô∏è SSI(all) attempt {attempt}/3 l·ªói: {last_err}")
        time.sleep(1.2)

    # B) fallback: chia theo s√†n
    all_df = []
    for attempt in range(1, 3+1):
        all_df.clear()
        ok_any = False
        for url in endpoints_by_floor:
            try:
                r = requests.get(url, headers=headers, timeout=(8, 18))
                r.raise_for_status()
                rows = r.json()
                df = _parse_df(rows)
                if not df.empty:
                    all_df.append(df)
                    ok_any = True
            except Exception as e:
                last_err = e
        if ok_any and all_df:
            big = pd.concat(all_df, ignore_index=True).drop_duplicates("ticker")
            tks = sorted(big["ticker"].unique().tolist())
            log(f"‚úÖ SSI(by-floor) <10k: {len(tks)} m√£.")
            cache_set("tickers_under_10k.json", {"tickers": tks, "src": "ssi"})
            return tks
        log(f"‚ö†Ô∏è SSI(by-floor) attempt {attempt}/3 l·ªói: {last_err}")
        time.sleep(1.2)

    # C) d√πng cache n·∫øu c√≥
    cached = cache_get("tickers_under_10k.json", ttl_sec=24*3600)
    if cached and cached.get("tickers"):
        log(f"üü° SSI l·ªói, d√πng cache: {len(cached['tickers'])} m√£")
        return cached["tickers"]
    
    # üëâ NEW: Fallback sang VNDIRECT ph√¢n trang nh·ªè (kh√¥ng n·∫∑ng)
    log("üîÅ Fallback: d√πng VNDIRECT stock_prices (paginate nh·ªè)‚Ä¶")
    tks_vnd = get_tickers_under_10k_from_vnd_prices()
    if tks_vnd:
        log(f"‚úÖ VNDIRECT fallback <10k: {len(tks_vnd)} m√£.")
        cache_set("tickers_under_10k.json", {"tickers": tks_vnd, "src": "vnd_price"})
        return tks_vnd
    
    log(f"‚ùå SSI kh√¥ng kh·∫£ d·ª•ng: {last_err}")
    return []

# ============================================================
# B2) FA T·ª™ VNDIRECT (C√ì CACHE 7 NG√ÄY) - CH·∫†Y RI√äNG
# ============================================================
def get_fr_one_ticker_vnd(tk):
    try:
        params = {"q": f"ticker:{tk}~reportType:QUARTER", "size": 8, "sort": "-yearQuarter"}
        r = SESSION.get(FR_URL, params=params, timeout=(8, 18))
        r.raise_for_status()
        return r.json().get("data", [])
    except Exception as e:
        log(f"‚ö†Ô∏è {tk} FR l·ªói: {e}")
        return []

def run_fa_update(tickers):
    """T·∫£i FA cho list tickers v√† l∆∞u cache 7 ng√†y: fa_cache.json"""
    if not tickers:
        log("‚ùå Kh√¥ng c√≥ tickers ƒë·ªÉ c·∫≠p nh·∫≠t FA.")
        return []
    log(f"üßæ C·∫≠p nh·∫≠t FA cho {len(tickers)} m√£ ‚Ä¶")
    out = []
    for i, tk in enumerate(tickers, 1):
        out.extend(get_fr_one_ticker_vnd(tk))
        if i % 25 == 0:
            log(f"‚Ä¶ƒë√£ l·∫•y {i}/{len(tickers)} m√£ FA")
            time.sleep(0.3)
    df = pd.DataFrame(out)
    cache_set("fa_cache.json", {"rows": out, "ts": int(time.time())})
    log(f"‚úÖ L∆∞u cache FA: {len(df)} d√≤ng (7 ng√†y)")
    return df

def load_fa_cache():
    cached = cache_get("fa_cache.json", ttl_sec=7*24*3600)
    if cached and cached.get("rows"):
        return pd.DataFrame(cached["rows"])
    return pd.DataFrame()

def analyze_fa(df_quarter: pd.DataFrame):
    """FA filter b·∫Øt bu·ªôc (gi·ªëng tr∆∞·ªõc): EPS>500, ROE>10, 0<PE<10, Debt/Equity<1, CFO TTM +, LNST YoY +, t·ªìn kho YoY <=30%."""
    if df_quarter.empty:
        return []
    fa_pass = []
    for ticker, sub in df_quarter.groupby("ticker"):
        sub = sub.sort_values(by="yearQuarter", ascending=False).head(8)
        latest = sub.iloc[0].to_dict()

        def f(row, key, default=0.0):
            try:
                v = row.get(key, default)
                return float(v) if pd.notna(v) else default
            except Exception:
                return default

        price = f(latest, "price")
        eps   = f(latest, "eps")
        pe    = f(latest, "pe")
        roe   = f(latest, "roe")
        inv   = f(latest, "inventory")
        liab  = f(latest, "liabilities")
        eq    = f(latest, "equity")

        lnst_q = pd.to_numeric(sub.get("netProfit"), errors="coerce").fillna(0.0).values.tolist()
        cfo_q  = pd.to_numeric(sub.get("netCashFlowFromOperatingActivities"), errors="coerce").fillna(0.0).values.tolist()

        inv_yoy = None
        if len(sub) >= 5:
            inv_yoy = f(sub.iloc[4].to_dict(), "inventory", None)

        # ƒêi·ªÅu ki·ªán
        if not (0 < price < 10000): continue
        if not (eps > 500): continue
        if not (roe > 10):  continue
        if not (0 < pe < 10): continue
        if eq <= 0 or (liab/eq) >= 1.0: continue
        cfo_ttm = sum(cfo_q[:4]) if len(cfo_q) >= 4 else sum(cfo_q)
        if cfo_ttm <= 0: continue
        lnst_yoy_ok = False
        if len(lnst_q) >= 5:
            lnst_yoy_ok = lnst_q[0] > lnst_q[4]
        elif len(lnst_q) >= 8:
            lnst_yoy_ok = sum(lnst_q[:4]) > sum(lnst_q[4:8])
        if not lnst_yoy_ok: continue
        if inv_yoy and inv_yoy > 0:
            if (inv - inv_yoy) / inv_yoy > 0.30:
                continue

        fa_pass.append({
            "ticker": ticker,
            "price": price,
            "eps": eps,
            "roe": roe,
            "pe": pe
        })
    log(f"‚úÖ FA PASS: {len(fa_pass)} m√£")
    return fa_pass

# ============================================================
# B3) TA T·ª™ VNDIRECT (REALTIME M·ªñI L·∫¶N CH·∫†Y)
# ============================================================
def get_ohlc_days_vnd(ticker, days=120):
    start = (datetime.now() - timedelta(days=days*2)).strftime("%Y-%m-%d")
    params = {"q": f"ticker:{ticker}~date:gte:{start}", "sort": "date", "size": 1000}
    try:
        r = SESSION.get(PRICE_URL, params=params, timeout=(8, 18))
        r.raise_for_status()
        data = r.json().get("data", [])
        if not data: return pd.DataFrame()
        df = pd.DataFrame(data)
        for c,n in [("adOpen","open"),("adHigh","high"),("adLow","low"),("adClose","close"),("adVolume","volume")]:
            if c in df.columns:
                df[n] = pd.to_numeric(df[c], errors="coerce")
        df = df[["date","open","high","low","close","volume"]].dropna().sort_values("date")
        return df.tail(150)
    except Exception as e:
        log(f"‚ö†Ô∏è OHLC {ticker} l·ªói: {e}")
        return pd.DataFrame()

def technical_signals(df: pd.DataFrame):
    """
    5 ƒëi·ªÅu ki·ªán TA:
      - ADX > 20 & DI+ > DI-
      - RSI > 50 v√† v·ª´a c·∫Øt l√™n
      - Break ƒë·ªânh 20 phi√™n
      - Volume tƒÉng 3 phi√™n li√™n ti·∫øp
      - Close > MA20 & Volume Spike
    """
    conds = {}
    if df is None or len(df) < 25:
        conds["enough_data"] = False
        conds["score_TA_true"] = 0
        return conds, 0

    rsi_ind = ta.momentum.RSIIndicator(close=df["close"], window=14)
    df["rsi"] = rsi_ind.rsi()
    adx_ind = ta.trend.ADXIndicator(high=df["high"], low=df["low"], close=df["close"], window=14)
    df["adx"] = adx_ind.adx()
    df["di_pos"] = adx_ind.adx_pos()
    df["di_neg"] = adx_ind.adx_neg()
    df["ma20"] = df["close"].rolling(20).mean()
    df["vol_ma20"] = df["volume"].rolling(20).mean()

    latest = df.iloc[-1]; prev = df.iloc[-2]
    conds["ADX>20_DI+>DI-"]   = bool((latest["adx"] > 20) and (latest["di_pos"] > latest["di_neg"]))
    conds["RSI>50_cross_up"]  = bool((latest["rsi"] > 50) and (prev["rsi"] <= 50))
    conds["Break_20_high"]    = bool(latest["close"] > float(df["close"].iloc[-20:-1].max()))
    conds["Vol_up_3_days"]    = bool(df["volume"].iloc[-1] > df["volume"].iloc[-2] > df["volume"].iloc[-3])
    conds["Close>MA20_VolSp"] = bool((latest["close"] > latest["ma20"]) and (latest["volume"] > 1.5 * latest["vol_ma20"]))

    score = sum(1 for v in conds.values() if v)
    conds["enough_data"] = True
    conds["score_TA_true"] = score
    return conds, score

# ============================================================
# G·ª¨I TELEGRAM
# ============================================================
def send_telegram(text):
    token = TELEGRAM_TOKEN; chat = TELEGRAM_CHAT_ID
    if not token or not chat:
        log("‚ùå Thi·∫øu TELEGRAM_TOKEN / TELEGRAM_CHAT_ID"); return
    try:
        url = f"https://api.telegram.org/bot{token}/sendMessage"
        r = requests.post(url, data={"chat_id": chat, "text": text}, timeout=15)
        if r.status_code == 200 and r.json().get("ok"):
            log("üì® Sent Telegram.")
        else:
            log(f"‚ùå Telegram {r.status_code}: {r.text}")
    except Exception as e:
        log(f"‚ùå Telegram error: {e}")

def format_msg(stocks):
    today = datetime.now().strftime("%d/%m/%Y")
    if not stocks:
        return f"üìâ [{today}] Kh√¥ng c√≥ m√£ n√†o ƒë·∫°t FA + TA."
    msg = f"üìà [{today}] M√£ <10k ƒë·∫°t FA + TA (‚â•3/5):\n\n"
    for s in stocks:
        msg += (f"‚Ä¢ {s['ticker']} | Gi√°: {int(s['price'])}ƒë | EPS:{int(s['eps'])} "
                f"| ROE:{s['roe']:.1f}% | P/E:{s['pe']:.1f} | TA‚úì:{s['ta_score']}/5\n")
    return msg

# ============================================================
# MAIN MODES
#   - python main.py list   -> ch·ªâ l·∫•y danh s√°ch <10k t·ª´ FireAnt
#   - python main.py fa     -> c·∫≠p nh·∫≠t & cache FA t·ª´ VNDIRECT
#   - python main.py scan   -> load FA cache -> qu√©t TA realtime
# ============================================================
def main():
    mode = (sys.argv[1] if len(sys.argv) > 1 else "scan").lower()
    log(f"üöÄ Start BOT mode={mode}")

    if mode == "list":
        tks = get_tickers_under_10k_from_ssi()
        log(f"Done list: {len(tks)} m√£")
        return

    if mode == "fa":
        tks = get_tickers_under_10k_from_ssi()
        if not tks:
            log("‚ö†Ô∏è Kh√¥ng c√≥ tickers t·ª´ ssi. D·ª´ng FA update.")
            return
        _ = run_fa_update(tks)
        log("FA update DONE.")
        return

    # mode == scan (default): d√πng FA cache + TA realtime
    df_fa_cache = load_fa_cache()
    fa_list = analyze_fa(df_fa_cache) if not df_fa_cache.empty else []
    
    if not fa_list:
        # üëâ TA-only: khi FA r·ªóng ho·∫∑c kh√¥ng pass
        log("üü† Kh√¥ng d√πng ƒë∆∞·ª£c FA ‚Üí chuy·ªÉn sang TA-only.")
        tks = get_tickers_under_10k_from_ssi()
        if not tks:
            send_telegram("‚ö†Ô∏è BOT: ssi/VNDirect ƒë·ªÅu kh√¥ng kh·∫£ d·ª•ng, t·∫°m d·ª´ng.")
            return
        # ch·∫°y TA cho danh s√°ch <10k, b·ªè b∆∞·ªõc FA
        final = []
        for i, tk in enumerate(tks, 1):
            log(f"[TA-only] {i}/{len(tks)} ‚Äî {tk}")
            df = get_ohlc_days_vnd(tk, days=180)
            conds, score = technical_signals(df)
            if conds.get("enough_data") and score >= 3:
                final.append({"ticker": tk, "price": float(df['close'].iloc[-1]), "eps": 0, "roe": 0, "pe": 0, "ta_score": score})
        send_telegram(format_msg(final))
        log(f"ALL DONE (TA-only). Final={len(final)}")
        return
    
    # ‚Ä¶ n·∫øu FA c√≥ d·ªØ li·ªáu th√¨ ch·∫°y flow c≈© (FA -> TA)
    final = []
    for i, it in enumerate(fa_list, 1):
        tk = it["ticker"]
        log(f"[TA] {i}/{len(fa_list)} ‚Äî {tk}")
        df = get_ohlc_days_vnd(tk, days=180)
        conds, score = technical_signals(df)
        if conds.get("enough_data") and score >= 3:
            final.append({**it, "ta_score": score})
    
    send_telegram(format_msg(final))
    log(f"ALL DONE. Final={len(final)}")

    final = []
    for i, it in enumerate(fa_list, 1):
        tk = it["ticker"]
        log(f"[TA] {i}/{len(fa_list)} ‚Äî {tk}")
        df = get_ohlc_days_vnd(tk, days=180)
        conds, score = technical_signals(df)
        if conds.get("enough_data") and score >= 3:
            final.append({**it, "ta_score": score})

    send_telegram(format_msg(final))
    log(f"ALL DONE. Final={len(final)}")

if __name__ == "__main__":
    main()
